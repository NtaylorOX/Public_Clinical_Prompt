{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8c3e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openprompt.data_utils import PROCESSORS\n",
    "import torch\n",
    "from openprompt.data_utils.utils import InputExample\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import ManualVerbalizer, ManualTemplate, MixedTemplate, SoftVerbalizer\n",
    "\n",
    "from openprompt.prompts import SoftTemplate\n",
    "from openprompt import PromptForClassification\n",
    "\n",
    "from openprompt.plms.seq2seq import T5TokenizerWrapper, T5LMTokenizerWrapper\n",
    "from transformers import T5Config, T5Tokenizer, T5ForConditionalGeneration\n",
    "from openprompt.data_utils.data_sampler import FewShotSampler\n",
    "from openprompt.plms import load_plm\n",
    "\n",
    "from utils import Mimic_ICD9_Processor, Mimic_ICD9_Triage_Processor, Mimic_Mortality_Processor\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from loguru import logger\n",
    "import json\n",
    "import itertools\n",
    "import torchmetrics.functional.classification as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fedc6c1",
   "metadata": {},
   "source": [
    "## Notebook for loading trained prompt models\n",
    " \n",
    "This is really just for playing around and testing - will be refined and implemented as a python script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bedbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix function\n",
    "def plot_confusion_matrix(cm, class_names, save_dir = None):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "\n",
    "    credit: https://towardsdatascience.com/exploring-confusion-matrix-evolution-on-tensorboard-e66b39f4ac12\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    font = FontProperties()\n",
    "    font.set_family('serif')\n",
    "    font.set_name('Times New Roman')\n",
    "    font.set_style('normal')\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "#     figure.savefig(f'{save_dir}/test_mtx.png')\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efba149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plotConfusionMatrix(cm, classes, annot = False):\n",
    "\n",
    "    cf_matrix = cm\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 10, index=[i for i in classes],\n",
    "                         columns=[i for i in classes])\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    return sn.heatmap(df_cm, annot=False).get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a21f6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate(prompt_model, dataloader, class_labels, mode = \"test\", use_cuda = True):\n",
    "    prompt_model.eval()\n",
    "\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    allscores = []\n",
    "    alllogits = []\n",
    "    allids = []\n",
    "    with torch.no_grad():\n",
    "        for step, inputs in tqdm(enumerate(dataloader), desc = \"evaluating\"):\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                \n",
    "            logits = prompt_model(inputs)\n",
    "            labels = inputs['label']\n",
    "            alllabels.extend(labels.cpu().tolist())\n",
    "            allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "            # guids already a list not a tensor\n",
    "            allids.extend(inputs['guid'])\n",
    "            alllogits.extend(logits.cpu().tolist())\n",
    "            \n",
    "            if len(class_labels) > 2:  \n",
    "                allscores.extend(torch.nn.functional.softmax(logits).cpu().tolist())\n",
    "            else:\n",
    "\n",
    "                allscores.extend(torch.nn.functional.softmax(logits)[:,1].cpu().tolist())\n",
    "                \n",
    "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "    print(f\"accuracy using manual method: {acc}\")\n",
    "\n",
    "    \n",
    "    print(f\"number unique preds: {len(np.unique(allpreds))}\")\n",
    "    print(f\"number unique labels: {len(np.unique(alllabels))}\")\n",
    "\n",
    "    \n",
    "    # get sklearn based metrics\n",
    "    f1 = f1_score(alllabels, allpreds, average = 'weighted')\n",
    "    prec = precision_score(alllabels, allpreds, average = 'weighted')\n",
    "    recall = recall_score(alllabels, allpreds, average = 'weighted')   \n",
    "    \n",
    "    # get confusion matric\n",
    "#     cm = metrics.confusion_matrix(preds = allpreds,target=alllabels, num_classes =50)\n",
    "    cm = confusion_matrix(alllabels, allpreds)    \n",
    "    \n",
    "    \n",
    "    # classification report\n",
    "    print(classification_report(alllabels, allpreds, target_names=class_labels))\n",
    "    \n",
    "    # save to dict\n",
    "    test_report = classification_report(alllabels, allpreds, target_names=class_labels, output_dict=True)\n",
    "    # now to file\n",
    "    df = pd.DataFrame(test_report).transpose()\n",
    "    df.to_csv(\"./test_class_report.csv\", index = False)\n",
    "    \n",
    "    # save logits etc\n",
    "    \n",
    "    results_dict = {}\n",
    "    results_dict['id'] = allids\n",
    "    results_dict['labels'] = alllabels\n",
    "    results_dict['pred_labels'] = allpreds\n",
    "    results_dict['logits'] = alllogits\n",
    "    results_dict['probas'] = allscores\n",
    "    # save dataframe and to csv\n",
    "    pd.DataFrame(results_dict).to_csv(\"./test_results.csv\", index =False)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#     cm_figure = plotConfusionMatrix(cm, class_labels)\n",
    "    cm_figure = plot_confusion_matrix(cm, class_labels)\n",
    "    \n",
    "    return acc, prec, recall, f1, cm, cm_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee70ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3190a6e0",
   "metadata": {},
   "source": [
    "the models produced by newest version of experiment_runner.py will save all parameters and ckpt in same place for easy loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4631e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with new params format\n",
    "import argparse\n",
    "ckpt_dir = \"../prompt-based-models/logs/mortality/emilyalsentzer/Bio_ClinicalBERT_tempmixed2_verbsoft0_full_100/version_16-03-2022--10-15/checkpoints/\"\n",
    "params_dir = f\"{ckpt_dir}/hparams.txt\"\n",
    "\n",
    "\n",
    "# works for python ide\n",
    "# parser = argparse.ArgumentParser()\n",
    "# args = parser.parse_args()\n",
    "# with open(f'{params_dir}', 'r') as f:\n",
    "#     args.__dict__ = json.load(f)\n",
    "\n",
    "\n",
    "# for notebook use following\n",
    "\n",
    "with open(f\"{params_dir}\") as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "plm_type = params[\"model\"]\n",
    "plm_name = params[\"model_name_or_path\"]\n",
    "template_type = params[\"template_type\"]\n",
    "template_id = params[\"template_id\"]\n",
    "verbalizer_type = params[\"verbalizer_type\"]\n",
    "verbalizer_id = params[\"verbalizer_id\"]\n",
    "data_dir = params[\"data_dir\"]\n",
    "dataset = params[\"dataset\"]\n",
    "scripts_path = params[\"scripts_path\"]\n",
    "init_from_vocab = params[\"init_from_vocab\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shouuld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3d169cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the model from checkpoint using torch in traditional way\n",
    "loaded_model = torch.load(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a70fcc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_model['template'][\"soft_embedding.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbbe3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shot': -1,\n",
       " 'seed': 144,\n",
       " 'plm_eval_mode': False,\n",
       " 'tune_plm': True,\n",
       " 'zero_shot': True,\n",
       " 'few_shot_n': 100,\n",
       " 'no_training': False,\n",
       " 'model': 'bert',\n",
       " 'model_name_or_path': 'emilyalsentzer/Bio_ClinicalBERT',\n",
       " 'project_root': '/mnt/sdg/niallt/saved_models/mimic-tasks/prompt-based-models/',\n",
       " 'template_id': 2,\n",
       " 'verbalizer_id': 0,\n",
       " 'template_type': 'mixed',\n",
       " 'verbalizer_type': 'soft',\n",
       " 'data_dir': '../mimic3-icd9-data/intermediary-data/',\n",
       " 'dataset': 'mortality',\n",
       " 'result_file': './mimic_icd9_top50/st_results/results.txt',\n",
       " 'scripts_path': './scripts/',\n",
       " 'class_labels_file': './scripts/mimic_icd9_top50/labels.txt',\n",
       " 'max_steps': 200000,\n",
       " 'prompt_lr': 0.3,\n",
       " 'warmup_step_prompt': 1000,\n",
       " 'num_epochs': 15,\n",
       " 'batch_size': 4,\n",
       " 'init_from_vocab': False,\n",
       " 'eval_every_steps': 100,\n",
       " 'soft_token_num': 20,\n",
       " 'optimizer': 'adafactor',\n",
       " 'gradient_accum_steps': 50,\n",
       " 'dev_run': False,\n",
       " 'gpu_num': 7,\n",
       " 'balance_data': False,\n",
       " 'ce_class_weights': False,\n",
       " 'sampler_weights': False,\n",
       " 'training_size': 'full',\n",
       " 'no_ckpt': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a177ecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'plm', 'template', and 'verbalizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ed3abaf5055a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# should just be able to load state dict using promptforclassification class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPromptForClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'plm', 'template', and 'verbalizer'"
     ]
    }
   ],
   "source": [
    "# should just be able to load state dict using promptforclassification class\n",
    "\n",
    "PromptForClassification().load_state_dict(state_dict = ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c69ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f80da080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_prompt_model(ckpt_dir, params_dir,\n",
    "                              use_cuda = True):\n",
    "    \n",
    "    '''\n",
    "    Function to reload an already trained promptmodelclassifier. At moment this still requires data/task specific \n",
    "    manual template or verbalizers to be setup as they need to point to correct scripts.\n",
    "    \n",
    "    Args:\n",
    "        ckpt_dir: path to save promptmodel\n",
    "        params_dir: path to parameters of training - in newest pipeline will be same as checkpoints dir\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # load in saved paramters for the trained model\n",
    "    with open(f\"{params_dir}\") as f:\n",
    "        params = json.load(f)\n",
    "    # set up the parameters based on the training config\n",
    "    plm_type = params[\"model\"]\n",
    "    plm_name = params[\"model_name_or_path\"]\n",
    "    template_type = params[\"template_type\"]\n",
    "    template_id = params[\"template_id\"]\n",
    "    verbalizer_type = params[\"verbalizer_type\"]\n",
    "    verbalizer_id = params[\"verbalizer_id\"]\n",
    "    data_dir = params[\"data_dir\"]\n",
    "    dataset_name = params[\"dataset\"]\n",
    "    scripts_path = params[\"scripts_path\"]\n",
    "    init_from_vocab = params[\"init_from_vocab\"]\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    tune_plm = params[\"tune_plm\"]\n",
    "    # set up datasets first    \n",
    "\n",
    "\n",
    "    dataset = {}\n",
    "    if dataset_name == \"icd9_50\":\n",
    "\n",
    "        logger.warning(f\"Using the following dataset: {dataset_name} \")\n",
    "        Processor = Mimic_ICD9_Processor\n",
    "        # update data_dir\n",
    "        data_dir = f\"{data_dir}/top_50_icd9\"\n",
    "\n",
    "        # get different splits\n",
    "        dataset['train'] = Processor().get_examples(data_dir = data_dir, mode = \"train\")\n",
    "        dataset['validation'] = Processor().get_examples(data_dir = data_dir, mode = \"valid\")\n",
    "        dataset['test'] = Processor().get_examples(data_dir = data_dir, mode = \"test\")[:500]\n",
    "        # the below class labels should align with the label encoder fitted to training data\n",
    "        # you will need to generate this class label text file first using the mimic processor with generate_class_labels flag to set true\n",
    "        # e.g. Processor().get_examples(data_dir = data_dir, mode = \"train\", generate_class_labels = True)[:10000]\n",
    "        class_labels =Processor().load_class_labels()\n",
    "        print(f\"number of classes: {len(class_labels)}\")\n",
    "        scriptsbase = f\"{scripts_path}/mimic_icd9_top50/\"\n",
    "        scriptformat = \"txt\"\n",
    "        max_seq_l = 480 # this should be specified according to the running GPU's capacity \n",
    "\n",
    "        batchsize_t = batch_size\n",
    "        batchsize_e = batch_size\n",
    "        gradient_accumulation_steps = 4\n",
    "        model_parallelize = False\n",
    "\n",
    "    elif dataset_name == \"icd9_triage\":\n",
    "        logger.warning(f\"Using the following dataset: {dataset_name} \")\n",
    "        Processor = Mimic_ICD9_Triage_Processor\n",
    "        # update data_dir\n",
    "        data_dir = f\"{data_dir}/triage\"\n",
    "\n",
    "        # get different splits\n",
    "        dataset['train'] = Processor().get_examples(data_dir = data_dir, mode = \"train\")\n",
    "        dataset['validation'] = Processor().get_examples(data_dir = data_dir, mode = \"valid\")\n",
    "        dataset['test'] = Processor().get_examples(data_dir = data_dir, mode = \"test\")\n",
    "        # the below class labels should align with the label encoder fitted to training data\n",
    "        # you will need to generate this class label text file first using the mimic processor with generate_class_labels flag to set true\n",
    "        # e.g. Processor().get_examples(data_dir = data_dir, mode = \"train\", generate_class_labels = True)[:10000]\n",
    "        class_labels =Processor().load_class_labels()\n",
    "        print(f\"number of classes: {len(class_labels)}\")\n",
    "        scriptsbase = f\"{scripts_path}/mimic_triage/\"\n",
    "        scriptformat = \"txt\"\n",
    "        max_seq_l = 480 # this should be specified according to the running GPU's capacity \n",
    "\n",
    "        batchsize_t = batch_size\n",
    "        batchsize_e = batch_size\n",
    "        gradient_accumulation_steps = 4\n",
    "        model_parallelize = False\n",
    "        \n",
    "    elif dataset_name == \"mortality\":\n",
    "        logger.warning(f\"Using the following dataset: {dataset_name} \")\n",
    "        Processor = Mimic_Mortality_Processor\n",
    "        # update data_dir\n",
    "        data_dir = \"../clinical-outcomes-data/mimic3-clinical-outcomes/mp/\"\n",
    "        \n",
    "        \n",
    "        dataset['train'] = Processor().get_examples(data_dir = data_dir, mode = \"train\", balance_data = False, class_weights=False, sampler_weights= False)[:1000]\n",
    "        dataset['validation'] = Processor().get_examples(data_dir = data_dir, mode = \"valid\", balance_data = False, class_weights=False, sampler_weights= False)[:500]\n",
    "        dataset['test'] = Processor().get_examples(data_dir = data_dir, mode = \"test\", balance_data = False, class_weights=False, sampler_weights= False)[:500]\n",
    "\n",
    "        # the below class labels should align with the label encoder fitted to training data\n",
    "        # you will need to generate this class label text file first using the mimic processor with generate_class_labels flag to set true\n",
    "        # e.g. Processor().get_examples(data_dir = args.data_dir, mode = \"train\", generate_class_labels = True)[:10000]\n",
    "        class_labels = Processor().load_class_labels()\n",
    "        print(f\"class labels: {class_labels}\")\n",
    "        print(f\"number of classes: {len(class_labels)}\")\n",
    "        scriptsbase = f\"{scripts_path}/mimic_mortality/\"\n",
    "        scriptformat = \"txt\"\n",
    "        max_seq_l = 480 # this should be specified according to the running GPU's capacity \n",
    "        batchsize_t = batch_size\n",
    "        batchsize_e = batch_size\n",
    "        gradient_accumulation_steps = 4\n",
    "        model_parallelize = False\n",
    "\n",
    "\n",
    "    else:\n",
    "        #TODO implement icd9 triage and mimic readmission\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    ######### set up the pretrained model etc ###########\n",
    "    \n",
    "    # initialise the pretrained language model\n",
    "    plm, tokenizer, model_config, WrapperClass = load_plm(plm_type, plm_name)    \n",
    "    \n",
    "    \n",
    "    # load the already trained prompt model, which will consist of a separate state_dict for the plm/template/verbalizer\n",
    "    loaded_model = torch.load(f\"{ckpt_dir}/best-checkpoint.ckpt\")\n",
    "    \n",
    "    \n",
    "    # now load the trained state_dict into the plm model if it was tuned during training\n",
    "    if tune_plm:\n",
    "        print(\"PLM was tuned during training - loading the weights!\")\n",
    "#         plm.load_state_dict(loaded_model['plm'])\n",
    "    else:\n",
    "        print(\"PLM was frozen during training to initializing from original pretrained weights!\")\n",
    "    \n",
    "    \n",
    "    # decide which template and verbalizer to use\n",
    "    if template_type == \"manual\":\n",
    "        print(f\"manual template selected, with id :{template_id}\")\n",
    "        mytemplate = ManualTemplate(tokenizer=tokenizer).from_file(f\"{scriptsbase}/manual_template.txt\", choice=template_id)\n",
    "\n",
    "    elif template_type == \"soft\":\n",
    "        print(f\"soft template selected, with id :{template_id}, will load template weights\")\n",
    "        mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, num_tokens=soft_token_num, initialize_from_vocab=init_from_vocab).from_file(f\"{scriptsbase}/soft_template.txt\", choice=template_id)\n",
    "        # now load the state_dict from ckpt\n",
    "#         mytemplate.load_state_dict(loaded_model['template'])\n",
    "\n",
    "    elif template_type == \"mixed\":\n",
    "        print(f\"mixed template selected, with id :{template_id}, will load template weights\")\n",
    "        mytemplate = MixedTemplate(model=plm, tokenizer=tokenizer).from_file(f\"{scriptsbase}/mixed_template.txt\", choice=template_id)\n",
    "#         mytemplate.load_state_dict(loaded_model['template'])\n",
    "    # now set verbalizer\n",
    "    if verbalizer_type == \"manual\":\n",
    "        print(f\"manual verbalizer selected, with id :{verbalizer_id}\")\n",
    "        myverbalizer = ManualVerbalizer(tokenizer, classes=class_labels).from_file(f\"{scriptsbase}/manual_verbalizer.{scriptformat}\", choice=verbalizer_id)\n",
    "\n",
    "    elif verbalizer_type == \"soft\":\n",
    "        print(f\"soft verbalizer selected!\")\n",
    "        myverbalizer = SoftVerbalizer(tokenizer, plm, num_classes=len(class_labels))\n",
    "        # now load the state dict from saved checkpoint\n",
    "#         myverbalizer.load_state_dict(loaded_model['verbalizer'])\n",
    "        \n",
    "#     # now bring it all together into the prompt classification model\n",
    "\n",
    "    trained_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer)\n",
    "    # now load state dicts\n",
    "    trained_model.load_state_dict(state_dict = loaded_model)\n",
    "    \n",
    "    # send to cuda\n",
    "    if use_cuda:\n",
    "        print(\"using cuda!\")\n",
    "        trained_model =  trained_model.cuda()\n",
    "    \n",
    "    # set up mimic data processors\n",
    "    # Below are multiple dataset examples, although right now just mimic ic9-top50. \n",
    "    \n",
    "    valid_dataloader = PromptDataLoader(dataset=dataset[\"validation\"], template=mytemplate, tokenizer=tokenizer, \n",
    "        tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_l, decoder_max_length=3, \n",
    "        batch_size=batchsize_e,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "        truncate_method=\"tail\")\n",
    "    # set up test dataloader\n",
    "    test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer, \n",
    "        tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_l, decoder_max_length=3, \n",
    "        batch_size=batchsize_e,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "        truncate_method=\"tail\")\n",
    "    \n",
    "    # run evaluation on validation and test\n",
    "    \n",
    "    print(f\"TEST RESULTS:\")\n",
    "    acc, prec, recall, f1, cm, cm_figure = evaluate(trained_model,test_dataloader, class_labels, \"test\", use_cuda)   \n",
    "    \n",
    "    \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    cm_figure\n",
    "    cm_figure.savefig(\"./test_cm.png\")\n",
    "    cm_figure.show()\n",
    "    \n",
    "    print(\"#\"*50)\n",
    "    print(f\"VALIDATION RESULTS:\")\n",
    "    acc, prec, recall, f1, cm, cm_figure = evaluate(trained_model,valid_dataloader, class_labels, \"valid\", use_cuda)   \n",
    "    \n",
    "    \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    cm_figure.show()\n",
    "    \n",
    "    \n",
    "    return trained_model, dataset, class_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337aa1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49ae4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 11:56:23.088 | WARNING  | __main__:load_trained_prompt_model:84 - Using the following dataset: mortality \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data\n",
      "data path provided was: ../clinical-outcomes-data/mimic3-clinical-outcomes/mp//train.csv\n",
      "label encoder idx to token:  {'alive': 0, 'deceased': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33954it [00:04, 7772.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading valid data\n",
      "data path provided was: ../clinical-outcomes-data/mimic3-clinical-outcomes/mp//valid.csv\n",
      "label encoder idx to token:  {'alive': 0, 'deceased': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4908it [00:00, 7986.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data\n",
      "data path provided was: ../clinical-outcomes-data/mimic3-clinical-outcomes/mp//test.csv\n",
      "label encoder idx to token:  {'alive': 0, 'deceased': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9822it [00:01, 7984.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels: ['alive', 'deceased']\n",
      "number of classes: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM was tuned during training - loading the weights!\n",
      "mixed template selected, with id :2, will load template weights\n",
      "soft verbalizer selected!\n",
      "using cuda!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 500it [00:04, 118.80it/s]\n",
      "tokenizing: 500it [00:04, 103.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 0it [00:00, ?it/s]/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "evaluating: 125it [00:10, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using manual method: 0.896\n",
      "number unique preds: 2\n",
      "number unique labels: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alive       0.92      0.97      0.94       447\n",
      "    deceased       0.52      0.25      0.33        53\n",
      "\n",
      "    accuracy                           0.90       500\n",
      "   macro avg       0.72      0.61      0.64       500\n",
      "weighted avg       0.87      0.90      0.88       500\n",
      "\n",
      "Accuracy: 0.896\n",
      "Precision: 0.8738357894736841\n",
      "Recall: 0.896\n",
      "F1: 0.8789125090383226\n",
      "##################################################\n",
      "VALIDATION RESULTS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 0it [00:00, ?it/s]/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "evaluating: 125it [00:10, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using manual method: 0.878\n",
      "number unique preds: 2\n",
      "number unique labels: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alive       0.92      0.94      0.93       445\n",
      "    deceased       0.43      0.35      0.38        55\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.68      0.64      0.66       500\n",
      "weighted avg       0.87      0.88      0.87       500\n",
      "\n",
      "Accuracy: 0.878\n",
      "Precision: 0.8672368421052631\n",
      "Recall: 0.878\n",
      "F1: 0.8719669503021333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model, dataset, class_labels = load_trained_prompt_model(ckpt_dir, params_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89fac420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 3, 0, 0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.template.soft_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50f632e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [unused1] [PAD] [unused2] [unused3] [PAD] [PAD]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.template.tokenizer.decode(trained_model.template.soft_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90d80809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.932297</td>\n",
       "      <td>445.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>55.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676435</td>\n",
       "      <td>0.644637</td>\n",
       "      <td>0.658068</td>\n",
       "      <td>500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.871967</td>\n",
       "      <td>500.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score  support\n",
       "0   0.921053  0.943820  0.932297  445.000\n",
       "1   0.431818  0.345455  0.383838   55.000\n",
       "2   0.878000  0.878000  0.878000    0.878\n",
       "3   0.676435  0.644637  0.658068  500.000\n",
       "4   0.867237  0.878000  0.871967  500.000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_report = pd.read_csv(\"./test_class_report.csv\")\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "639aaa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>logits</th>\n",
       "      <th>probas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.047472596168518, -1.5696438550949097]</td>\n",
       "      <td>0.068045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.7488698959350586, 0.41361546516418457]</td>\n",
       "      <td>0.208292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.9810081720352173, -1.1894588470458984]</td>\n",
       "      <td>0.040292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.569184422492981, -0.47117742896080017]</td>\n",
       "      <td>0.261080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.2246674299240112, -0.9159674048423767]</td>\n",
       "      <td>0.105210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.588822364807129, -1.5362037420272827]</td>\n",
       "      <td>0.005911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.5265350341796875, -0.2700766623020172]</td>\n",
       "      <td>0.057508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5904316902160645, -0.7121673226356506]</td>\n",
       "      <td>0.213728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.0319576263427734, -2.3137478828430176]</td>\n",
       "      <td>0.004746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.49176886677742004, 0.3558225929737091]</td>\n",
       "      <td>0.466066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  labels  pred_labels                                     logits  \\\n",
       "0      0       0            0   [1.047472596168518, -1.5696438550949097]   \n",
       "1      1       0            0  [1.7488698959350586, 0.41361546516418457]   \n",
       "2      2       1            0  [1.9810081720352173, -1.1894588470458984]   \n",
       "3      3       0            0  [0.569184422492981, -0.47117742896080017]   \n",
       "4      4       0            0  [1.2246674299240112, -0.9159674048423767]   \n",
       "..   ...     ...          ...                                        ...   \n",
       "495  495       0            0   [3.588822364807129, -1.5362037420272827]   \n",
       "496  496       0            0  [2.5265350341796875, -0.2700766623020172]   \n",
       "497  497       0            0  [0.5904316902160645, -0.7121673226356506]   \n",
       "498  498       0            0  [3.0319576263427734, -2.3137478828430176]   \n",
       "499  499       0            0  [0.49176886677742004, 0.3558225929737091]   \n",
       "\n",
       "       probas  \n",
       "0    0.068045  \n",
       "1    0.208292  \n",
       "2    0.040292  \n",
       "3    0.261080  \n",
       "4    0.105210  \n",
       "..        ...  \n",
       "495  0.005911  \n",
       "496  0.057508  \n",
       "497  0.213728  \n",
       "498  0.004746  \n",
       "499  0.466066  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the saved test results\n",
    "\n",
    "test_results = pd.read_csv(\"./test_results.csv\")\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9f444a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.047472596168518, -1.5696438550949097]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.7488698959350586, 0.41361546516418457]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.9810081720352173, -1.1894588470458984]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.569184422492981, -0.47117742896080017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[1.2246674299240112, -0.9159674048423767]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>[3.588822364807129, -1.5362037420272827]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>[2.5265350341796875, -0.2700766623020172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[0.5904316902160645, -0.7121673226356506]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>[3.0319576263427734, -2.3137478828430176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>[0.49176886677742004, 0.3558225929737091]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                     logits\n",
       "0      0   [1.047472596168518, -1.5696438550949097]\n",
       "1      1  [1.7488698959350586, 0.41361546516418457]\n",
       "2      2  [1.9810081720352173, -1.1894588470458984]\n",
       "3      3  [0.569184422492981, -0.47117742896080017]\n",
       "4      4  [1.2246674299240112, -0.9159674048423767]\n",
       "..   ...                                        ...\n",
       "495  495   [3.588822364807129, -1.5362037420272827]\n",
       "496  496  [2.5265350341796875, -0.2700766623020172]\n",
       "497  497  [0.5904316902160645, -0.7121673226356506]\n",
       "498  498  [3.0319576263427734, -2.3137478828430176]\n",
       "499  499  [0.49176886677742004, 0.3558225929737091]\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logits = pd.read_csv(\"./test_logits.csv\")\n",
    "test_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06825d",
   "metadata": {},
   "source": [
    "# BELOW TO BE REMOVED - WAS PLAYING AROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996d15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./checkpoints/icd9_50/emilyalsentzer/Bio_ClinicalBERT_tempmanual2_verbsoft0/version_21-01-2022--13-41/checkpoint.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f201fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7292dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plm', 'template', 'verbalizer'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0306a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "state_dict() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bec79c1bb7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPromptForClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: state_dict() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "PromptForClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original way of instantiating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec56dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can load the trained state dict for the plm like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82065d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba73c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace9cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35af0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template\n",
    "\n",
    "mytemplate = ManualTemplate(tokenizer=tokenizer).from_file(\"scripts/mimic_icd9_top50/manual_template.txt\", choice=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97efa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft template\n",
    "\n",
    "soft_template = SoftTemplate(model=plm, tokenizer=tokenizer, num_tokens=20, initialize_from_vocab=True).from_file(f\"scripts/mimic_icd9_top50/soft_template.txt\", choice=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4115c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftTemplate(\n",
       "  (raw_embedding): Embedding(28996, 768, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "112dc64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('[PAD]', 0),\n",
       "             ('[unused1]', 1),\n",
       "             ('[unused2]', 2),\n",
       "             ('[unused3]', 3),\n",
       "             ('[unused4]', 4),\n",
       "             ('[unused5]', 5),\n",
       "             ('[unused6]', 6),\n",
       "             ('[unused7]', 7),\n",
       "             ('[unused8]', 8),\n",
       "             ('[unused9]', 9),\n",
       "             ('[unused10]', 10),\n",
       "             ('[unused11]', 11),\n",
       "             ('[unused12]', 12),\n",
       "             ('[unused13]', 13),\n",
       "             ('[unused14]', 14),\n",
       "             ('[unused15]', 15),\n",
       "             ('[unused16]', 16),\n",
       "             ('[unused17]', 17),\n",
       "             ('[unused18]', 18),\n",
       "             ('[unused19]', 19),\n",
       "             ('[unused20]', 20),\n",
       "             ('[unused21]', 21),\n",
       "             ('[unused22]', 22),\n",
       "             ('[unused23]', 23),\n",
       "             ('[unused24]', 24),\n",
       "             ('[unused25]', 25),\n",
       "             ('[unused26]', 26),\n",
       "             ('[unused27]', 27),\n",
       "             ('[unused28]', 28),\n",
       "             ('[unused29]', 29),\n",
       "             ('[unused30]', 30),\n",
       "             ('[unused31]', 31),\n",
       "             ('[unused32]', 32),\n",
       "             ('[unused33]', 33),\n",
       "             ('[unused34]', 34),\n",
       "             ('[unused35]', 35),\n",
       "             ('[unused36]', 36),\n",
       "             ('[unused37]', 37),\n",
       "             ('[unused38]', 38),\n",
       "             ('[unused39]', 39),\n",
       "             ('[unused40]', 40),\n",
       "             ('[unused41]', 41),\n",
       "             ('[unused42]', 42),\n",
       "             ('[unused43]', 43),\n",
       "             ('[unused44]', 44),\n",
       "             ('[unused45]', 45),\n",
       "             ('[unused46]', 46),\n",
       "             ('[unused47]', 47),\n",
       "             ('[unused48]', 48),\n",
       "             ('[unused49]', 49),\n",
       "             ('[unused50]', 50),\n",
       "             ('[unused51]', 51),\n",
       "             ('[unused52]', 52),\n",
       "             ('[unused53]', 53),\n",
       "             ('[unused54]', 54),\n",
       "             ('[unused55]', 55),\n",
       "             ('[unused56]', 56),\n",
       "             ('[unused57]', 57),\n",
       "             ('[unused58]', 58),\n",
       "             ('[unused59]', 59),\n",
       "             ('[unused60]', 60),\n",
       "             ('[unused61]', 61),\n",
       "             ('[unused62]', 62),\n",
       "             ('[unused63]', 63),\n",
       "             ('[unused64]', 64),\n",
       "             ('[unused65]', 65),\n",
       "             ('[unused66]', 66),\n",
       "             ('[unused67]', 67),\n",
       "             ('[unused68]', 68),\n",
       "             ('[unused69]', 69),\n",
       "             ('[unused70]', 70),\n",
       "             ('[unused71]', 71),\n",
       "             ('[unused72]', 72),\n",
       "             ('[unused73]', 73),\n",
       "             ('[unused74]', 74),\n",
       "             ('[unused75]', 75),\n",
       "             ('[unused76]', 76),\n",
       "             ('[unused77]', 77),\n",
       "             ('[unused78]', 78),\n",
       "             ('[unused79]', 79),\n",
       "             ('[unused80]', 80),\n",
       "             ('[unused81]', 81),\n",
       "             ('[unused82]', 82),\n",
       "             ('[unused83]', 83),\n",
       "             ('[unused84]', 84),\n",
       "             ('[unused85]', 85),\n",
       "             ('[unused86]', 86),\n",
       "             ('[unused87]', 87),\n",
       "             ('[unused88]', 88),\n",
       "             ('[unused89]', 89),\n",
       "             ('[unused90]', 90),\n",
       "             ('[unused91]', 91),\n",
       "             ('[unused92]', 92),\n",
       "             ('[unused93]', 93),\n",
       "             ('[unused94]', 94),\n",
       "             ('[unused95]', 95),\n",
       "             ('[unused96]', 96),\n",
       "             ('[unused97]', 97),\n",
       "             ('[unused98]', 98),\n",
       "             ('[unused99]', 99),\n",
       "             ('[UNK]', 100),\n",
       "             ('[CLS]', 101),\n",
       "             ('[SEP]', 102),\n",
       "             ('[MASK]', 103),\n",
       "             ('[unused100]', 104),\n",
       "             ('[unused101]', 105),\n",
       "             ('!', 106),\n",
       "             ('\"', 107),\n",
       "             ('#', 108),\n",
       "             ('$', 109),\n",
       "             ('%', 110),\n",
       "             ('&', 111),\n",
       "             (\"'\", 112),\n",
       "             ('(', 113),\n",
       "             (')', 114),\n",
       "             ('*', 115),\n",
       "             ('+', 116),\n",
       "             (',', 117),\n",
       "             ('-', 118),\n",
       "             ('.', 119),\n",
       "             ('/', 120),\n",
       "             ('0', 121),\n",
       "             ('1', 122),\n",
       "             ('2', 123),\n",
       "             ('3', 124),\n",
       "             ('4', 125),\n",
       "             ('5', 126),\n",
       "             ('6', 127),\n",
       "             ('7', 128),\n",
       "             ('8', 129),\n",
       "             ('9', 130),\n",
       "             (':', 131),\n",
       "             (';', 132),\n",
       "             ('<', 133),\n",
       "             ('=', 134),\n",
       "             ('>', 135),\n",
       "             ('?', 136),\n",
       "             ('@', 137),\n",
       "             ('A', 138),\n",
       "             ('B', 139),\n",
       "             ('C', 140),\n",
       "             ('D', 141),\n",
       "             ('E', 142),\n",
       "             ('F', 143),\n",
       "             ('G', 144),\n",
       "             ('H', 145),\n",
       "             ('I', 146),\n",
       "             ('J', 147),\n",
       "             ('K', 148),\n",
       "             ('L', 149),\n",
       "             ('M', 150),\n",
       "             ('N', 151),\n",
       "             ('O', 152),\n",
       "             ('P', 153),\n",
       "             ('Q', 154),\n",
       "             ('R', 155),\n",
       "             ('S', 156),\n",
       "             ('T', 157),\n",
       "             ('U', 158),\n",
       "             ('V', 159),\n",
       "             ('W', 160),\n",
       "             ('X', 161),\n",
       "             ('Y', 162),\n",
       "             ('Z', 163),\n",
       "             ('[', 164),\n",
       "             ('\\\\', 165),\n",
       "             (']', 166),\n",
       "             ('^', 167),\n",
       "             ('_', 168),\n",
       "             ('`', 169),\n",
       "             ('a', 170),\n",
       "             ('b', 171),\n",
       "             ('c', 172),\n",
       "             ('d', 173),\n",
       "             ('e', 174),\n",
       "             ('f', 175),\n",
       "             ('g', 176),\n",
       "             ('h', 177),\n",
       "             ('i', 178),\n",
       "             ('j', 179),\n",
       "             ('k', 180),\n",
       "             ('l', 181),\n",
       "             ('m', 182),\n",
       "             ('n', 183),\n",
       "             ('o', 184),\n",
       "             ('p', 185),\n",
       "             ('q', 186),\n",
       "             ('r', 187),\n",
       "             ('s', 188),\n",
       "             ('t', 189),\n",
       "             ('u', 190),\n",
       "             ('v', 191),\n",
       "             ('w', 192),\n",
       "             ('x', 193),\n",
       "             ('y', 194),\n",
       "             ('z', 195),\n",
       "             ('{', 196),\n",
       "             ('|', 197),\n",
       "             ('}', 198),\n",
       "             ('~', 199),\n",
       "             ('', 200),\n",
       "             ('', 201),\n",
       "             ('', 202),\n",
       "             ('', 203),\n",
       "             ('', 204),\n",
       "             ('', 205),\n",
       "             ('', 206),\n",
       "             ('', 207),\n",
       "             ('', 208),\n",
       "             ('', 209),\n",
       "             ('', 210),\n",
       "             ('', 211),\n",
       "             ('', 212),\n",
       "             ('', 213),\n",
       "             ('', 214),\n",
       "             ('', 215),\n",
       "             ('', 216),\n",
       "             ('', 217),\n",
       "             ('', 218),\n",
       "             ('', 219),\n",
       "             ('', 220),\n",
       "             ('', 221),\n",
       "             ('', 222),\n",
       "             ('', 223),\n",
       "             ('', 224),\n",
       "             ('', 225),\n",
       "             ('', 226),\n",
       "             ('', 227),\n",
       "             ('', 228),\n",
       "             ('', 229),\n",
       "             ('', 230),\n",
       "             ('', 231),\n",
       "             ('', 232),\n",
       "             ('', 233),\n",
       "             ('', 234),\n",
       "             ('', 235),\n",
       "             ('', 236),\n",
       "             ('', 237),\n",
       "             ('', 238),\n",
       "             ('', 239),\n",
       "             ('', 240),\n",
       "             ('', 241),\n",
       "             ('', 242),\n",
       "             ('', 243),\n",
       "             ('', 244),\n",
       "             ('', 245),\n",
       "             ('', 246),\n",
       "             ('', 247),\n",
       "             ('', 248),\n",
       "             ('', 249),\n",
       "             ('', 250),\n",
       "             ('', 251),\n",
       "             ('', 252),\n",
       "             ('', 253),\n",
       "             ('', 254),\n",
       "             ('', 255),\n",
       "             ('', 256),\n",
       "             ('', 257),\n",
       "             ('', 258),\n",
       "             ('', 259),\n",
       "             ('', 260),\n",
       "             ('', 261),\n",
       "             ('', 262),\n",
       "             ('', 263),\n",
       "             ('', 264),\n",
       "             ('', 265),\n",
       "             ('', 266),\n",
       "             ('', 267),\n",
       "             ('', 268),\n",
       "             ('', 269),\n",
       "             ('', 270),\n",
       "             ('', 271),\n",
       "             ('', 272),\n",
       "             ('', 273),\n",
       "             ('', 274),\n",
       "             ('', 275),\n",
       "             ('', 276),\n",
       "             ('', 277),\n",
       "             ('', 278),\n",
       "             ('', 279),\n",
       "             ('', 280),\n",
       "             ('', 281),\n",
       "             ('', 282),\n",
       "             ('', 283),\n",
       "             ('', 284),\n",
       "             ('', 285),\n",
       "             ('', 286),\n",
       "             ('', 287),\n",
       "             ('', 288),\n",
       "             ('', 289),\n",
       "             ('', 290),\n",
       "             ('', 291),\n",
       "             ('', 292),\n",
       "             ('', 293),\n",
       "             ('', 294),\n",
       "             ('', 295),\n",
       "             ('', 296),\n",
       "             ('', 297),\n",
       "             ('', 298),\n",
       "             ('', 299),\n",
       "             ('', 300),\n",
       "             ('', 301),\n",
       "             ('', 302),\n",
       "             ('', 303),\n",
       "             ('', 304),\n",
       "             ('', 305),\n",
       "             ('', 306),\n",
       "             ('', 307),\n",
       "             ('', 308),\n",
       "             ('', 309),\n",
       "             ('', 310),\n",
       "             ('', 311),\n",
       "             ('', 312),\n",
       "             ('', 313),\n",
       "             ('', 314),\n",
       "             ('', 315),\n",
       "             ('', 316),\n",
       "             ('', 317),\n",
       "             ('', 318),\n",
       "             ('', 319),\n",
       "             ('', 320),\n",
       "             ('', 321),\n",
       "             ('', 322),\n",
       "             ('', 323),\n",
       "             ('', 324),\n",
       "             ('', 325),\n",
       "             ('', 326),\n",
       "             ('', 327),\n",
       "             ('', 328),\n",
       "             ('', 329),\n",
       "             ('', 330),\n",
       "             ('', 331),\n",
       "             ('', 332),\n",
       "             ('', 333),\n",
       "             ('', 334),\n",
       "             ('', 335),\n",
       "             ('', 336),\n",
       "             ('', 337),\n",
       "             ('', 338),\n",
       "             ('', 339),\n",
       "             ('', 340),\n",
       "             ('', 341),\n",
       "             ('', 342),\n",
       "             ('', 343),\n",
       "             ('', 344),\n",
       "             ('', 345),\n",
       "             ('', 346),\n",
       "             ('', 347),\n",
       "             ('', 348),\n",
       "             ('', 349),\n",
       "             ('', 350),\n",
       "             ('', 351),\n",
       "             ('', 352),\n",
       "             ('', 353),\n",
       "             ('', 354),\n",
       "             ('', 355),\n",
       "             ('', 356),\n",
       "             ('', 357),\n",
       "             ('', 358),\n",
       "             ('', 359),\n",
       "             ('', 360),\n",
       "             ('', 361),\n",
       "             ('', 362),\n",
       "             ('', 363),\n",
       "             ('', 364),\n",
       "             ('', 365),\n",
       "             ('', 366),\n",
       "             ('', 367),\n",
       "             ('', 368),\n",
       "             ('', 369),\n",
       "             ('', 370),\n",
       "             ('', 371),\n",
       "             ('', 372),\n",
       "             ('', 373),\n",
       "             ('', 374),\n",
       "             ('', 375),\n",
       "             ('', 376),\n",
       "             ('', 377),\n",
       "             ('', 378),\n",
       "             ('', 379),\n",
       "             ('', 380),\n",
       "             ('', 381),\n",
       "             ('', 382),\n",
       "             ('', 383),\n",
       "             ('', 384),\n",
       "             ('', 385),\n",
       "             ('', 386),\n",
       "             ('', 387),\n",
       "             ('', 388),\n",
       "             ('', 389),\n",
       "             ('', 390),\n",
       "             ('', 391),\n",
       "             ('', 392),\n",
       "             ('', 393),\n",
       "             ('', 394),\n",
       "             ('', 395),\n",
       "             ('', 396),\n",
       "             ('', 397),\n",
       "             ('', 398),\n",
       "             ('', 399),\n",
       "             ('', 400),\n",
       "             ('', 401),\n",
       "             ('', 402),\n",
       "             ('', 403),\n",
       "             ('', 404),\n",
       "             ('', 405),\n",
       "             ('', 406),\n",
       "             ('', 407),\n",
       "             ('', 408),\n",
       "             ('', 409),\n",
       "             ('', 410),\n",
       "             ('', 411),\n",
       "             ('', 412),\n",
       "             ('', 413),\n",
       "             ('', 414),\n",
       "             ('', 415),\n",
       "             ('', 416),\n",
       "             ('', 417),\n",
       "             ('', 418),\n",
       "             ('', 419),\n",
       "             ('', 420),\n",
       "             ('', 421),\n",
       "             ('', 422),\n",
       "             ('', 423),\n",
       "             ('', 424),\n",
       "             ('', 425),\n",
       "             ('', 426),\n",
       "             ('', 427),\n",
       "             ('', 428),\n",
       "             ('', 429),\n",
       "             ('', 430),\n",
       "             ('', 431),\n",
       "             ('', 432),\n",
       "             ('', 433),\n",
       "             ('', 434),\n",
       "             ('', 435),\n",
       "             ('', 436),\n",
       "             ('', 437),\n",
       "             ('', 438),\n",
       "             ('', 439),\n",
       "             ('', 440),\n",
       "             ('', 441),\n",
       "             ('', 442),\n",
       "             ('', 443),\n",
       "             ('', 444),\n",
       "             ('', 445),\n",
       "             ('', 446),\n",
       "             ('', 447),\n",
       "             ('', 448),\n",
       "             ('', 449),\n",
       "             ('', 450),\n",
       "             ('', 451),\n",
       "             ('', 452),\n",
       "             ('', 453),\n",
       "             ('', 454),\n",
       "             ('', 455),\n",
       "             ('', 456),\n",
       "             ('', 457),\n",
       "             ('', 458),\n",
       "             ('', 459),\n",
       "             ('', 460),\n",
       "             ('', 461),\n",
       "             ('', 462),\n",
       "             ('', 463),\n",
       "             ('', 464),\n",
       "             ('', 465),\n",
       "             ('', 466),\n",
       "             ('', 467),\n",
       "             ('', 468),\n",
       "             ('', 469),\n",
       "             ('', 470),\n",
       "             ('', 471),\n",
       "             ('', 472),\n",
       "             ('', 473),\n",
       "             ('', 474),\n",
       "             ('', 475),\n",
       "             ('', 476),\n",
       "             ('', 477),\n",
       "             ('', 478),\n",
       "             ('', 479),\n",
       "             ('', 480),\n",
       "             ('', 481),\n",
       "             ('', 482),\n",
       "             ('', 483),\n",
       "             ('', 484),\n",
       "             ('', 485),\n",
       "             ('', 486),\n",
       "             ('', 487),\n",
       "             ('', 488),\n",
       "             ('', 489),\n",
       "             ('', 490),\n",
       "             ('', 491),\n",
       "             ('', 492),\n",
       "             ('', 493),\n",
       "             ('', 494),\n",
       "             ('', 495),\n",
       "             ('', 496),\n",
       "             ('', 497),\n",
       "             ('', 498),\n",
       "             ('', 499),\n",
       "             ('', 500),\n",
       "             ('', 501),\n",
       "             ('', 502),\n",
       "             ('', 503),\n",
       "             ('', 504),\n",
       "             ('', 505),\n",
       "             ('', 506),\n",
       "             ('', 507),\n",
       "             ('', 508),\n",
       "             ('', 509),\n",
       "             ('', 510),\n",
       "             ('', 511),\n",
       "             ('', 512),\n",
       "             ('', 513),\n",
       "             ('', 514),\n",
       "             ('', 515),\n",
       "             ('', 516),\n",
       "             ('', 517),\n",
       "             ('', 518),\n",
       "             ('', 519),\n",
       "             ('', 520),\n",
       "             ('', 521),\n",
       "             ('', 522),\n",
       "             ('', 523),\n",
       "             ('', 524),\n",
       "             ('', 525),\n",
       "             ('', 526),\n",
       "             ('', 527),\n",
       "             ('', 528),\n",
       "             ('', 529),\n",
       "             ('', 530),\n",
       "             ('', 531),\n",
       "             ('', 532),\n",
       "             ('', 533),\n",
       "             ('', 534),\n",
       "             ('', 535),\n",
       "             ('', 536),\n",
       "             ('', 537),\n",
       "             ('', 538),\n",
       "             ('', 539),\n",
       "             ('', 540),\n",
       "             ('', 541),\n",
       "             ('', 542),\n",
       "             ('', 543),\n",
       "             ('', 544),\n",
       "             ('', 545),\n",
       "             ('', 546),\n",
       "             ('', 547),\n",
       "             ('', 548),\n",
       "             ('', 549),\n",
       "             ('', 550),\n",
       "             ('', 551),\n",
       "             ('', 552),\n",
       "             ('', 553),\n",
       "             ('', 554),\n",
       "             ('', 555),\n",
       "             ('', 556),\n",
       "             ('', 557),\n",
       "             ('', 558),\n",
       "             ('', 559),\n",
       "             ('', 560),\n",
       "             ('', 561),\n",
       "             ('', 562),\n",
       "             ('', 563),\n",
       "             ('', 564),\n",
       "             ('', 565),\n",
       "             ('', 566),\n",
       "             ('', 567),\n",
       "             ('', 568),\n",
       "             ('', 569),\n",
       "             ('', 570),\n",
       "             ('', 571),\n",
       "             ('', 572),\n",
       "             ('', 573),\n",
       "             ('', 574),\n",
       "             ('', 575),\n",
       "             ('', 576),\n",
       "             ('', 577),\n",
       "             ('', 578),\n",
       "             ('', 579),\n",
       "             ('', 580),\n",
       "             ('', 581),\n",
       "             ('', 582),\n",
       "             ('', 583),\n",
       "             ('', 584),\n",
       "             ('', 585),\n",
       "             ('', 586),\n",
       "             ('', 587),\n",
       "             ('', 588),\n",
       "             ('', 589),\n",
       "             ('', 590),\n",
       "             ('', 591),\n",
       "             ('', 592),\n",
       "             ('', 593),\n",
       "             ('', 594),\n",
       "             ('', 595),\n",
       "             ('', 596),\n",
       "             ('', 597),\n",
       "             ('', 598),\n",
       "             ('', 599),\n",
       "             ('', 600),\n",
       "             ('', 601),\n",
       "             ('', 602),\n",
       "             ('', 603),\n",
       "             ('', 604),\n",
       "             ('', 605),\n",
       "             ('', 606),\n",
       "             ('', 607),\n",
       "             ('', 608),\n",
       "             ('', 609),\n",
       "             ('', 610),\n",
       "             ('', 611),\n",
       "             ('', 612),\n",
       "             ('', 613),\n",
       "             ('', 614),\n",
       "             ('', 615),\n",
       "             ('', 616),\n",
       "             ('', 617),\n",
       "             ('', 618),\n",
       "             ('', 619),\n",
       "             ('', 620),\n",
       "             ('', 621),\n",
       "             ('', 622),\n",
       "             ('', 623),\n",
       "             ('', 624),\n",
       "             ('', 625),\n",
       "             ('', 626),\n",
       "             ('', 627),\n",
       "             ('', 628),\n",
       "             ('', 629),\n",
       "             ('', 630),\n",
       "             ('', 631),\n",
       "             ('', 632),\n",
       "             ('', 633),\n",
       "             ('', 634),\n",
       "             ('', 635),\n",
       "             ('', 636),\n",
       "             ('', 637),\n",
       "             ('', 638),\n",
       "             ('', 639),\n",
       "             ('', 640),\n",
       "             ('', 641),\n",
       "             ('', 642),\n",
       "             ('', 643),\n",
       "             ('', 644),\n",
       "             ('', 645),\n",
       "             ('', 646),\n",
       "             ('', 647),\n",
       "             ('', 648),\n",
       "             ('', 649),\n",
       "             ('', 650),\n",
       "             ('', 651),\n",
       "             ('', 652),\n",
       "             ('', 653),\n",
       "             ('', 654),\n",
       "             ('', 655),\n",
       "             ('', 656),\n",
       "             ('', 657),\n",
       "             ('', 658),\n",
       "             ('', 659),\n",
       "             ('', 660),\n",
       "             ('', 661),\n",
       "             ('', 662),\n",
       "             ('', 663),\n",
       "             ('', 664),\n",
       "             ('', 665),\n",
       "             ('', 666),\n",
       "             ('', 667),\n",
       "             ('', 668),\n",
       "             ('', 669),\n",
       "             ('', 670),\n",
       "             ('', 671),\n",
       "             ('', 672),\n",
       "             ('', 673),\n",
       "             ('', 674),\n",
       "             ('', 675),\n",
       "             ('', 676),\n",
       "             ('', 677),\n",
       "             ('', 678),\n",
       "             ('', 679),\n",
       "             ('', 680),\n",
       "             ('', 681),\n",
       "             ('', 682),\n",
       "             ('', 683),\n",
       "             ('', 684),\n",
       "             ('', 685),\n",
       "             ('', 686),\n",
       "             ('', 687),\n",
       "             ('', 688),\n",
       "             ('', 689),\n",
       "             ('', 690),\n",
       "             ('', 691),\n",
       "             ('', 692),\n",
       "             ('', 693),\n",
       "             ('', 694),\n",
       "             ('', 695),\n",
       "             ('', 696),\n",
       "             ('', 697),\n",
       "             ('', 698),\n",
       "             ('', 699),\n",
       "             ('', 700),\n",
       "             ('', 701),\n",
       "             ('', 702),\n",
       "             ('', 703),\n",
       "             ('', 704),\n",
       "             ('', 705),\n",
       "             ('', 706),\n",
       "             ('', 707),\n",
       "             ('', 708),\n",
       "             ('', 709),\n",
       "             ('', 710),\n",
       "             ('', 711),\n",
       "             ('', 712),\n",
       "             ('', 713),\n",
       "             ('', 714),\n",
       "             ('', 715),\n",
       "             ('', 716),\n",
       "             ('', 717),\n",
       "             ('', 718),\n",
       "             ('', 719),\n",
       "             ('', 720),\n",
       "             ('', 721),\n",
       "             ('', 722),\n",
       "             ('', 723),\n",
       "             ('', 724),\n",
       "             ('', 725),\n",
       "             ('', 726),\n",
       "             ('', 727),\n",
       "             ('', 728),\n",
       "             ('', 729),\n",
       "             ('', 730),\n",
       "             ('', 731),\n",
       "             ('', 732),\n",
       "             ('', 733),\n",
       "             ('', 734),\n",
       "             ('', 735),\n",
       "             ('', 736),\n",
       "             ('', 737),\n",
       "             ('', 738),\n",
       "             ('', 739),\n",
       "             ('', 740),\n",
       "             ('', 741),\n",
       "             ('', 742),\n",
       "             ('', 743),\n",
       "             ('', 744),\n",
       "             ('', 745),\n",
       "             ('', 746),\n",
       "             ('', 747),\n",
       "             ('', 748),\n",
       "             ('', 749),\n",
       "             ('', 750),\n",
       "             ('', 751),\n",
       "             ('', 752),\n",
       "             ('', 753),\n",
       "             ('', 754),\n",
       "             ('', 755),\n",
       "             ('', 756),\n",
       "             ('', 757),\n",
       "             ('', 758),\n",
       "             ('', 759),\n",
       "             ('', 760),\n",
       "             ('', 761),\n",
       "             ('', 762),\n",
       "             ('', 763),\n",
       "             ('', 764),\n",
       "             ('', 765),\n",
       "             ('', 766),\n",
       "             ('', 767),\n",
       "             ('', 768),\n",
       "             ('', 769),\n",
       "             ('', 770),\n",
       "             ('', 771),\n",
       "             ('', 772),\n",
       "             ('', 773),\n",
       "             ('', 774),\n",
       "             ('', 775),\n",
       "             ('', 776),\n",
       "             ('', 777),\n",
       "             ('', 778),\n",
       "             ('', 779),\n",
       "             ('', 780),\n",
       "             ('', 781),\n",
       "             ('', 782),\n",
       "             ('', 783),\n",
       "             ('', 784),\n",
       "             ('', 785),\n",
       "             ('', 786),\n",
       "             ('', 787),\n",
       "             ('', 788),\n",
       "             ('', 789),\n",
       "             ('', 790),\n",
       "             ('', 791),\n",
       "             ('', 792),\n",
       "             ('', 793),\n",
       "             ('', 794),\n",
       "             ('', 795),\n",
       "             ('', 796),\n",
       "             ('', 797),\n",
       "             ('', 798),\n",
       "             ('', 799),\n",
       "             ('', 800),\n",
       "             ('', 801),\n",
       "             ('', 802),\n",
       "             ('', 803),\n",
       "             ('', 804),\n",
       "             ('', 805),\n",
       "             ('', 806),\n",
       "             ('', 807),\n",
       "             ('', 808),\n",
       "             ('', 809),\n",
       "             ('', 810),\n",
       "             ('', 811),\n",
       "             ('', 812),\n",
       "             ('', 813),\n",
       "             ('', 814),\n",
       "             ('', 815),\n",
       "             ('', 816),\n",
       "             ('', 817),\n",
       "             ('', 818),\n",
       "             ('', 819),\n",
       "             ('', 820),\n",
       "             ('', 821),\n",
       "             ('', 822),\n",
       "             ('', 823),\n",
       "             ('', 824),\n",
       "             ('', 825),\n",
       "             ('', 826),\n",
       "             ('', 827),\n",
       "             ('', 828),\n",
       "             ('', 829),\n",
       "             ('', 830),\n",
       "             ('', 831),\n",
       "             ('', 832),\n",
       "             ('', 833),\n",
       "             ('', 834),\n",
       "             ('', 835),\n",
       "             ('', 836),\n",
       "             ('', 837),\n",
       "             ('', 838),\n",
       "             ('', 839),\n",
       "             ('', 840),\n",
       "             ('', 841),\n",
       "             ('', 842),\n",
       "             ('', 843),\n",
       "             ('', 844),\n",
       "             ('', 845),\n",
       "             ('', 846),\n",
       "             ('', 847),\n",
       "             ('', 848),\n",
       "             ('', 849),\n",
       "             ('', 850),\n",
       "             ('', 851),\n",
       "             ('', 852),\n",
       "             ('', 853),\n",
       "             ('', 854),\n",
       "             ('', 855),\n",
       "             ('', 856),\n",
       "             ('', 857),\n",
       "             ('', 858),\n",
       "             ('', 859),\n",
       "             ('', 860),\n",
       "             ('', 861),\n",
       "             ('', 862),\n",
       "             ('', 863),\n",
       "             ('', 864),\n",
       "             ('', 865),\n",
       "             ('', 866),\n",
       "             ('', 867),\n",
       "             ('', 868),\n",
       "             ('', 869),\n",
       "             ('', 870),\n",
       "             ('', 871),\n",
       "             ('', 872),\n",
       "             ('', 873),\n",
       "             ('', 874),\n",
       "             ('', 875),\n",
       "             ('', 876),\n",
       "             ('', 877),\n",
       "             ('', 878),\n",
       "             ('', 879),\n",
       "             ('', 880),\n",
       "             ('', 881),\n",
       "             ('', 882),\n",
       "             ('', 883),\n",
       "             ('', 884),\n",
       "             ('', 885),\n",
       "             ('', 886),\n",
       "             ('', 887),\n",
       "             ('', 888),\n",
       "             ('', 889),\n",
       "             ('', 890),\n",
       "             ('', 891),\n",
       "             ('', 892),\n",
       "             ('', 893),\n",
       "             ('', 894),\n",
       "             ('', 895),\n",
       "             ('', 896),\n",
       "             ('', 897),\n",
       "             ('', 898),\n",
       "             ('', 899),\n",
       "             ('', 900),\n",
       "             ('', 901),\n",
       "             ('', 902),\n",
       "             ('', 903),\n",
       "             ('', 904),\n",
       "             ('', 905),\n",
       "             ('', 906),\n",
       "             ('', 907),\n",
       "             ('', 908),\n",
       "             ('', 909),\n",
       "             ('', 910),\n",
       "             ('', 911),\n",
       "             ('', 912),\n",
       "             ('', 913),\n",
       "             ('', 914),\n",
       "             ('', 915),\n",
       "             ('', 916),\n",
       "             ('', 917),\n",
       "             ('', 918),\n",
       "             ('', 919),\n",
       "             ('', 920),\n",
       "             ('', 921),\n",
       "             ('', 922),\n",
       "             ('', 923),\n",
       "             ('', 924),\n",
       "             ('', 925),\n",
       "             ('', 926),\n",
       "             ('', 927),\n",
       "             ('', 928),\n",
       "             ('', 929),\n",
       "             ('', 930),\n",
       "             ('', 931),\n",
       "             ('', 932),\n",
       "             ('', 933),\n",
       "             ('', 934),\n",
       "             ('', 935),\n",
       "             ('', 936),\n",
       "             ('', 937),\n",
       "             ('', 938),\n",
       "             ('', 939),\n",
       "             ('', 940),\n",
       "             ('', 941),\n",
       "             ('', 942),\n",
       "             ('', 943),\n",
       "             ('', 944),\n",
       "             ('', 945),\n",
       "             ('', 946),\n",
       "             ('', 947),\n",
       "             ('', 948),\n",
       "             ('', 949),\n",
       "             ('', 950),\n",
       "             ('', 951),\n",
       "             ('', 952),\n",
       "             ('', 953),\n",
       "             ('', 954),\n",
       "             ('', 955),\n",
       "             ('', 956),\n",
       "             ('', 957),\n",
       "             ('', 958),\n",
       "             ('', 959),\n",
       "             ('', 960),\n",
       "             ('', 961),\n",
       "             ('', 962),\n",
       "             ('', 963),\n",
       "             ('', 964),\n",
       "             ('', 965),\n",
       "             ('', 966),\n",
       "             ('', 967),\n",
       "             ('', 968),\n",
       "             ('', 969),\n",
       "             ('', 970),\n",
       "             ('', 971),\n",
       "             ('', 972),\n",
       "             ('', 973),\n",
       "             ('', 974),\n",
       "             ('', 975),\n",
       "             ('', 976),\n",
       "             ('', 977),\n",
       "             ('', 978),\n",
       "             ('', 979),\n",
       "             ('', 980),\n",
       "             ('', 981),\n",
       "             ('', 982),\n",
       "             ('', 983),\n",
       "             ('', 984),\n",
       "             ('', 985),\n",
       "             ('', 986),\n",
       "             ('', 987),\n",
       "             ('', 988),\n",
       "             ('', 989),\n",
       "             ('', 990),\n",
       "             ('', 991),\n",
       "             ('', 992),\n",
       "             ('', 993),\n",
       "             ('', 994),\n",
       "             ('', 995),\n",
       "             ('', 996),\n",
       "             ('', 997),\n",
       "             ('', 998),\n",
       "             ('', 999),\n",
       "             ...])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f2fa7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try the verbalizer\n",
    "\n",
    "soft_verb = SoftVerbalizer(tokenizer, plm, num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35293840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now load the state dict from saved checkpoint\n",
    "soft_verb.load_state_dict(loaded_model['verbalizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6bb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6618a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now bring it all together into the prompt classification model\n",
    "\n",
    "trained_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=soft_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f56ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptForClassification(\n",
       "  (prompt_model): PromptModel(\n",
       "    (plm): BertForMaskedLM(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls): BertOnlyMLMHead(\n",
       "        (predictions): BertLMPredictionHead(\n",
       "          (transform): BertPredictionHeadTransform(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (template): ManualTemplate()\n",
       "  )\n",
       "  (verbalizer): SoftVerbalizer(\n",
       "    (head): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=50, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f31ff5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.10.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2af6ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_prompt_model(ckpt_dir, plm_type,\n",
    "                              plm_name, template_type,\n",
    "                             template_id, verbalizer_type, verbalizer_id, scripts_path = \"./scripts/\",\n",
    "                             init_from_vocab = True, data_dir = \"../data/intermediary-data/\",\n",
    "                              dataset_name = \"icd9_50\", use_cuda = True):\n",
    "    \n",
    "    '''\n",
    "    Function to reload an already trained promptmodelclassifier. At moment this still requires data/task specific \n",
    "    manual template or verbalizers to be setup as they need to point to correct scripts.\n",
    "    \n",
    "    Args:\n",
    "        ckpt_dir: path to save promptmodel\n",
    "        plm_type: the language model type e.g. bert, t5, gpt\n",
    "        plm_name: the name of the pretrained model/checkpoint e.g. bert-base-uncased\n",
    "        template_type: manual, mixed or soft prompt template?\n",
    "        template_id: which row or idx of the file in scripts will the template be e.g. scripts/manual_template[0] is line 1\n",
    "        verbalizer_type: this maps the tokens (mask prediction) to class labels. Can be one-to-one, many-to-one, \n",
    "                        and can be manual or soft\n",
    "        verbalizer_id: which row or idx of the file in scripts will the verbalizer be e.g. scripts/manual_verbalizer[0] is line 1\n",
    "        scriptnase: path to scripts directory    \n",
    "        init_from_vocab: whether soft templates should be initialized from the plms vocabulary\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # set up datasets first\n",
    "    \n",
    "    dataset_name = dataset_name\n",
    "    data_dir = data_dir\n",
    "    batch_size = 4\n",
    "\n",
    "\n",
    "    dataset = {}\n",
    "    if dataset_name == \"icd9_50\":\n",
    "\n",
    "        logger.warning(f\"Using the following dataset: {dataset_name} \")\n",
    "        Processor = Mimic_ICD9_Processor\n",
    "        # update data_dir\n",
    "        data_dir = f\"{data_dir}/top_50_icd9\"\n",
    "\n",
    "        # get different splits\n",
    "        dataset['train'] = Processor().get_examples(data_dir = data_dir, mode = \"train\")\n",
    "        dataset['validation'] = Processor().get_examples(data_dir = data_dir, mode = \"valid\")\n",
    "        dataset['test'] = Processor().get_examples(data_dir = data_dir, mode = \"test\")[:500]\n",
    "        # the below class labels should align with the label encoder fitted to training data\n",
    "        # you will need to generate this class label text file first using the mimic processor with generate_class_labels flag to set true\n",
    "        # e.g. Processor().get_examples(data_dir = data_dir, mode = \"train\", generate_class_labels = True)[:10000]\n",
    "        class_labels =Processor().load_class_labels()\n",
    "        print(f\"number of classes: {len(class_labels)}\")\n",
    "        scriptsbase = f\"{scripts_path}/mimic_icd9_top50/\"\n",
    "        scriptformat = \"txt\"\n",
    "        max_seq_l = 480 # this should be specified according to the running GPU's capacity \n",
    "\n",
    "        batchsize_t = batch_size\n",
    "        batchsize_e = batch_size\n",
    "        gradient_accumulation_steps = 4\n",
    "        model_parallelize = False\n",
    "\n",
    "    elif dataset_name == \"icd9_triage\":\n",
    "        logger.warning(f\"Using the following dataset: {dataset_name} \")\n",
    "        Processor = Mimic_ICD9_Triage_Processor\n",
    "        # update data_dir\n",
    "        data_dir = f\"{data_dir}/triage\"\n",
    "\n",
    "        # get different splits\n",
    "        dataset['train'] = Processor().get_examples(data_dir = data_dir, mode = \"train\")\n",
    "        dataset['validation'] = Processor().get_examples(data_dir = data_dir, mode = \"valid\")\n",
    "        dataset['test'] = Processor().get_examples(data_dir = data_dir, mode = \"test\")[:500]\n",
    "        # the below class labels should align with the label encoder fitted to training data\n",
    "        # you will need to generate this class label text file first using the mimic processor with generate_class_labels flag to set true\n",
    "        # e.g. Processor().get_examples(data_dir = data_dir, mode = \"train\", generate_class_labels = True)[:10000]\n",
    "        class_labels =Processor().load_class_labels()\n",
    "        print(f\"number of classes: {len(class_labels)}\")\n",
    "        scriptsbase = f\"{scripts_path}/mimic_triage/\"\n",
    "        scriptformat = \"txt\"\n",
    "        max_seq_l = 480 # this should be specified according to the running GPU's capacity \n",
    "\n",
    "        batchsize_t = batch_size\n",
    "        batchsize_e = batch_size\n",
    "        gradient_accumulation_steps = 4\n",
    "        model_parallelize = False\n",
    "    else:\n",
    "        #TODO implement icd9 triage and mimic readmission\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    ######### set up the pretrained model etc ###########\n",
    "    \n",
    "    # initialise the pretrained language model\n",
    "    plm, tokenizer, model_config, WrapperClass = load_plm(plm_type, plm_name)\n",
    "    \n",
    "    # load the already trained prompt model, which will consist of a separate state_dict for the plm/template/verbalizer\n",
    "    loaded_model = torch.load(ckpt_dir)\n",
    "    \n",
    "    \n",
    "    # now load the trained state_dict into the plm model\n",
    "    plm.load_state_dict(loaded_model['plm'])\n",
    "    \n",
    "    \n",
    "    # decide which template and verbalizer to use\n",
    "    if template_type == \"manual\":\n",
    "        print(f\"manual template selected, with id :{template_id}\")\n",
    "        mytemplate = ManualTemplate(tokenizer=tokenizer).from_file(f\"{scriptsbase}/manual_template.txt\", choice=template_id)\n",
    "\n",
    "    elif template_type == \"soft\":\n",
    "        print(f\"soft template selected, with id :{template_id}\")\n",
    "        mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, num_tokens=soft_token_num, initialize_from_vocab=init_from_vocab).from_file(f\"{scriptsbase}/soft_template.txt\", choice=template_id)\n",
    "        # now load the state_dict from ckpt\n",
    "        mytemplate.load_state_dict(loaded_model['template'])\n",
    "\n",
    "    elif template_type == \"mixed\":\n",
    "        print(f\"mixed template selected, with id :{template_id}\")\n",
    "        mytemplate = MixedTemplate(model=plm, tokenizer=tokenizer).from_file(f\"{scriptsbase}/mixed_template.txt\", choice=template_id)\n",
    "        \n",
    "    # now set verbalizer\n",
    "    if verbalizer_type == \"manual\":\n",
    "        print(f\"manual verbalizer selected, with id :{verbalizer_id}\")\n",
    "        myverbalizer = ManualVerbalizer(tokenizer, classes=class_labels).from_file(f\"{scriptsbase}/manual_verbalizer.{scriptformat}\", choice=verbalizer_id)\n",
    "\n",
    "    elif verbalizer_type == \"soft\":\n",
    "        print(f\"soft verbalizer selected!\")\n",
    "        myverbalizer = SoftVerbalizer(tokenizer, plm, num_classes=50)\n",
    "        # now load the state dict from saved checkpoint\n",
    "        myverbalizer.load_state_dict(loaded_model['verbalizer'])\n",
    "        \n",
    "    # now bring it all together into the prompt classification model\n",
    "\n",
    "    trained_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer)\n",
    "    \n",
    "    # send to cuda\n",
    "    if use_cuda:\n",
    "        print(\"using cuda!\")\n",
    "        trained_model =  trained_model.cuda()\n",
    "    \n",
    "    # set up mimic data processors\n",
    "    # Below are multiple dataset examples, although right now just mimic ic9-top50. \n",
    "    \n",
    "    # set up test dataloader\n",
    "    test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer, \n",
    "        tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_l, decoder_max_length=3, \n",
    "        batch_size=batchsize_e,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "        truncate_method=\"tail\")\n",
    "    \n",
    "    # run evaluation\n",
    "    acc, prec, recall, f1, cm, cm_figure = evaluate(trained_model,test_dataloader, class_labels, \"test\", use_cuda)\n",
    "    \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    cm_figure.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    return trained_model, dataset, class_labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84af34",
   "metadata": {},
   "source": [
    "at moment this is a bit crude - as hparams have to be manually coded. And the hparams txt files are not easily usable at moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ae68031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 14:56:21.229 | WARNING  | __main__:load_trained_prompt_model:36 - Using the following dataset: icd9_50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data\n",
      "data path provided was: ../data/intermediary-data//top_50_icd9/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14360it [00:01, 8765.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading valid data\n",
      "data path provided was: ../data/intermediary-data//top_50_icd9/valid.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4693it [00:00, 8973.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data\n",
      "data path provided was: ../data/intermediary-data//top_50_icd9/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4754it [00:00, 8876.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual template selected, with id :2\n",
      "soft verbalizer selected!\n",
      "using cuda!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 500it [00:13, 36.52it/s]\n",
      "evaluating: 125it [00:10, 12.23it/s]\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using manual method: 0.692\n",
      "[30, 39, 13, 48, 18, 26, 33, 21, 2, 24, 16, 38, 43, 13, 37, 6, 31, 48, 13, 4, 29, 13, 1, 25, 30, 22, 32, 23, 13, 13, 4, 22, 12, 44, 12, 13, 16, 13, 13, 48, 47, 13, 22, 32, 13, 27, 34, 22, 15, 30, 17, 48, 1, 13, 4, 5, 25, 10, 13, 4, 13, 4, 7, 16, 4, 21, 34, 19, 47, 17, 22, 40, 36, 1, 14, 31, 30, 13, 16, 4, 33, 13, 3, 47, 11, 13, 4, 13, 13, 47, 42, 13, 37, 12, 34, 13, 21, 6, 16, 12, 27, 4, 13, 24, 7, 46, 27, 47, 13, 13, 27, 10, 48, 22, 32, 4, 28, 32, 44, 2, 16, 16, 19, 13, 13, 12, 25, 11, 5, 10, 4, 46, 20, 47, 14, 21, 16, 12, 15, 13, 11, 44, 16, 47, 30, 4, 47, 32, 13, 9, 29, 16, 7, 2, 31, 12, 22, 46, 32, 14, 15, 38, 24, 2, 32, 12, 7, 18, 12, 37, 13, 40, 12, 48, 25, 24, 4, 12, 19, 35, 4, 4, 47, 47, 47, 15, 32, 23, 4, 47, 13, 10, 12, 41, 4, 19, 12, 40, 11, 36, 22, 20, 5, 47, 32, 13, 17, 13, 47, 18, 37, 4, 14, 21, 22, 35, 16, 4, 43, 33, 47, 13, 39, 35, 18, 45, 46, 13, 11, 11, 12, 19, 7, 32, 46, 13, 46, 30, 19, 29, 31, 28, 47, 31, 16, 48, 22, 13, 22, 47, 22, 4, 37, 13, 13, 27, 24, 44, 12, 12, 13, 46, 46, 16, 47, 13, 22, 37, 32, 4, 12, 20, 48, 46, 31, 38, 36, 47, 4, 10, 13, 20, 13, 4, 13, 30, 48, 13, 3, 47, 4, 15, 48, 31, 48, 22, 15, 2, 24, 24, 47, 10, 47, 12, 13, 10, 43, 27, 31, 33, 16, 40, 46, 42, 12, 3, 5, 13, 47, 16, 4, 15, 28, 24, 4, 4, 13, 48, 11, 26, 42, 16, 17, 25, 1, 4, 43, 45, 13, 4, 32, 36, 12, 16, 16, 17, 4, 13, 12, 2, 47, 46, 4, 10, 14, 4, 13, 31, 11, 4, 47, 12, 31, 22, 13, 4, 13, 13, 45, 12, 13, 16, 19, 39, 22, 47, 13, 13, 13, 13, 0, 12, 21, 49, 19, 27, 13, 48, 30, 39, 13, 15, 12, 47, 12, 16, 44, 7, 14, 36, 16, 33, 47, 12, 12, 47, 10, 21, 10, 22, 47, 20, 20, 47, 9, 47, 12, 4, 18, 4, 29, 5, 24, 16, 13, 13, 9, 18, 20, 16, 27, 30, 46, 12, 4, 13, 21, 4, 42, 13, 7, 27, 23, 22, 19, 12, 13, 15, 46, 16, 14, 47, 13, 12, 25, 12, 32, 13, 47, 46, 49, 13, 13, 32, 46, 4, 6, 13, 4, 20, 47, 44, 46, 21, 30, 13, 43, 16, 39, 40, 34, 22, 13, 26, 22, 40, 21, 40, 48, 13, 19, 22, 19, 46, 16, 48, 1, 40, 32, 13]\n",
      "[19, 39, 13, 48, 18, 25, 32, 22, 2, 24, 16, 38, 4, 13, 37, 6, 33, 48, 16, 4, 29, 15, 4, 8, 30, 22, 32, 42, 13, 13, 41, 22, 10, 44, 12, 12, 16, 13, 13, 48, 47, 15, 22, 4, 13, 27, 40, 21, 15, 32, 17, 48, 41, 12, 31, 5, 25, 10, 13, 4, 13, 30, 7, 16, 32, 21, 34, 19, 47, 17, 22, 35, 37, 4, 14, 31, 30, 13, 13, 1, 6, 13, 4, 47, 11, 13, 4, 15, 11, 46, 42, 13, 37, 13, 40, 13, 21, 6, 16, 12, 27, 1, 13, 13, 7, 46, 27, 47, 13, 13, 27, 12, 48, 25, 32, 4, 28, 32, 44, 4, 16, 16, 20, 13, 13, 30, 25, 10, 5, 10, 4, 46, 32, 48, 4, 22, 16, 12, 13, 13, 11, 44, 16, 47, 30, 5, 47, 6, 13, 16, 29, 16, 6, 37, 32, 13, 22, 31, 4, 14, 15, 3, 24, 4, 4, 12, 22, 18, 12, 37, 13, 29, 12, 48, 26, 24, 4, 12, 15, 40, 2, 32, 46, 47, 47, 15, 25, 23, 4, 47, 13, 10, 13, 41, 30, 16, 13, 40, 11, 36, 22, 19, 5, 47, 32, 13, 17, 13, 47, 12, 37, 4, 14, 21, 22, 35, 16, 4, 43, 33, 47, 13, 39, 35, 18, 45, 46, 13, 11, 11, 15, 32, 7, 12, 46, 24, 46, 4, 13, 29, 32, 28, 47, 31, 16, 48, 22, 13, 22, 47, 22, 31, 37, 13, 13, 27, 24, 44, 12, 12, 13, 46, 46, 16, 47, 13, 25, 37, 32, 6, 12, 20, 48, 46, 12, 38, 40, 47, 32, 10, 13, 19, 13, 32, 13, 30, 48, 13, 4, 47, 38, 15, 48, 32, 48, 4, 15, 39, 24, 24, 47, 10, 47, 31, 13, 13, 4, 27, 32, 32, 16, 35, 46, 42, 13, 32, 5, 13, 47, 16, 4, 15, 28, 24, 31, 4, 13, 47, 11, 32, 42, 16, 18, 25, 43, 4, 43, 45, 12, 14, 12, 36, 12, 16, 16, 17, 31, 13, 40, 4, 47, 46, 4, 10, 14, 31, 13, 31, 11, 4, 47, 12, 30, 22, 13, 2, 13, 28, 45, 12, 12, 16, 19, 39, 21, 47, 13, 13, 13, 13, 45, 28, 21, 49, 17, 27, 13, 48, 30, 39, 16, 15, 12, 47, 13, 16, 44, 7, 32, 36, 16, 33, 47, 12, 12, 47, 10, 21, 12, 26, 47, 19, 20, 47, 16, 47, 12, 32, 18, 4, 29, 30, 24, 16, 13, 13, 9, 18, 43, 16, 27, 4, 46, 32, 4, 13, 21, 4, 42, 13, 7, 27, 42, 22, 4, 12, 13, 15, 46, 16, 14, 47, 13, 13, 25, 12, 32, 13, 47, 46, 49, 13, 13, 32, 46, 40, 6, 13, 4, 18, 47, 45, 46, 21, 32, 13, 40, 16, 39, 35, 44, 22, 13, 25, 22, 37, 21, 36, 47, 13, 12, 22, 19, 46, 16, 48, 20, 34, 32, 12]\n",
      "number unique preds: 49\n",
      "number unique labels: 49\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 32  1  0]\n",
      " [ 0  0  0 ...  2 13  0]\n",
      " [ 0  0  0 ...  0  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0380       0.00      0.00      0.00         1\n",
      "       03811       0.00      0.00      0.00         5\n",
      "       03842       0.33      0.17      0.22         6\n",
      "       03849       0.00      0.00      0.00         3\n",
      "        0389       0.51      0.45      0.48        40\n",
      "         042       0.80      0.80      0.80         5\n",
      "        1623       0.43      1.00      0.60         3\n",
      "        1983       1.00      0.71      0.83         7\n",
      "       29181       0.00      0.00      0.00         0\n",
      "        3962       1.00      0.33      0.50         3\n",
      "       41011       0.78      0.70      0.74        10\n",
      "       41041       0.88      0.88      0.88         8\n",
      "       41071       0.61      0.58      0.59        33\n",
      "       41401       0.84      0.82      0.83        74\n",
      "       41519       0.83      0.71      0.77         7\n",
      "        4240       0.62      0.89      0.73         9\n",
      "        4241       0.83      0.96      0.89        26\n",
      "        4271       0.80      0.80      0.80         5\n",
      "       42731       0.71      0.83      0.77         6\n",
      "        4280       0.43      0.27      0.33        11\n",
      "       42823       0.50      0.25      0.33         8\n",
      "         430       0.80      0.80      0.80        10\n",
      "         431       0.83      0.71      0.77        21\n",
      "        4321       1.00      0.33      0.50         3\n",
      "       43310       0.89      0.89      0.89         9\n",
      "       43411       0.44      0.67      0.53         6\n",
      "       43491       0.00      0.00      0.00         3\n",
      "        4373       1.00      1.00      1.00         9\n",
      "       44101       0.60      1.00      0.75         3\n",
      "        4414       0.80      1.00      0.89         4\n",
      "         486       0.50      0.50      0.50        10\n",
      "        5070       0.30      0.30      0.30        10\n",
      "       51881       0.30      0.53      0.38        15\n",
      "       51884       0.67      0.40      0.50         5\n",
      "       53240       0.50      0.25      0.33         4\n",
      "       56212       0.40      0.67      0.50         3\n",
      "        5712       0.75      0.60      0.67         5\n",
      "        5715       0.67      1.00      0.80         6\n",
      "        5761       0.67      0.67      0.67         3\n",
      "        5770       0.83      1.00      0.91         5\n",
      "        5789       0.12      0.12      0.12         8\n",
      "        5849       0.33      1.00      0.50         1\n",
      "       85221       0.67      1.00      0.80         4\n",
      "       99662       0.50      0.40      0.44         5\n",
      "       99811       0.83      0.83      0.83         6\n",
      "       99859       0.60      1.00      0.75         3\n",
      "       V3000       0.89      0.94      0.91        17\n",
      "       V3001       0.94      0.91      0.93        35\n",
      "       V3101       0.93      0.87      0.90        15\n",
      "       V3401       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.61      0.63      0.60       500\n",
      "weighted avg       0.70      0.69      0.68       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niallt/venvs/nlp_projects/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-cde8c9d3f084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                              \u001b[0mtemplate_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbalizer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbalizer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripts_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./scripts/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                              \u001b[0minit_from_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/intermediary-data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                               dataset_name = \"icd9_50\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-d27b642757da>\u001b[0m in \u001b[0;36mload_trained_prompt_model\u001b[0;34m(ckpt_dir, plm_type, plm_name, template_type, template_id, verbalizer_type, verbalizer_id, scripts_path, init_from_vocab, data_dir, dataset_name, use_cuda)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_figure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-c2d43f3fca5c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(prompt_model, dataloader, class_labels, mode, use_cuda)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#     cm_figure = plotConfusionMatrix(cm, class_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mcm_figure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_figure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-5efb713439a1>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(cm, class_names, save_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"white\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"black\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to refactor the entire training pipeline to store everything including template types etc in a reloadable way\n",
    "# BEST PLAN IS TO SHIFT TO PYTORCH LIGHTNING FOR TRAINING\n",
    "\n",
    "# set up params based on the saved ckpt name\n",
    "ckpt_dir = \"./checkpoints/icd9_50/emilyalsentzer/Bio_ClinicalBERT_tempmanual2_verbsoft0/version_21-01-2022--13-41/checkpoint.ckpt\"\n",
    "plm_type = \"bert\"\n",
    "plm_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "# plm_name = \"bert-base-cased\"\n",
    "template_type = \"manual\"\n",
    "template_id = 2\n",
    "verbalizer_type = \"soft\"\n",
    "verbalizer_id = 0 \n",
    "dataset_name = \"icd9_50\"\n",
    "\n",
    "\n",
    "\n",
    "trained_prompt_model, dataset, class_labels = load_trained_prompt_model(ckpt_dir,plm_type,\n",
    "                              plm_name, template_type,\n",
    "                             template_id, verbalizer_type, verbalizer_id, scripts_path = \"./scripts/\",\n",
    "                             init_from_vocab = True, data_dir = \"../data/intermediary-data/\",\n",
    "                              dataset_name = \"icd9_50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbe8fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae8c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-cased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.10.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_prompt_model.plm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9b8659f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0380',\n",
       " '03811',\n",
       " '03842',\n",
       " '03849',\n",
       " '0389',\n",
       " '042',\n",
       " '1623',\n",
       " '1983',\n",
       " '29181',\n",
       " '3962',\n",
       " '41011',\n",
       " '41041',\n",
       " '41071',\n",
       " '41401',\n",
       " '41519',\n",
       " '4240',\n",
       " '4241',\n",
       " '4271',\n",
       " '42731',\n",
       " '4280',\n",
       " '42823',\n",
       " '430',\n",
       " '431',\n",
       " '4321',\n",
       " '43310',\n",
       " '43411',\n",
       " '43491',\n",
       " '4373',\n",
       " '44101',\n",
       " '4414',\n",
       " '486',\n",
       " '5070',\n",
       " '51881',\n",
       " '51884',\n",
       " '53240',\n",
       " '56212',\n",
       " '5712',\n",
       " '5715',\n",
       " '5761',\n",
       " '5770',\n",
       " '5789',\n",
       " '5849',\n",
       " '85221',\n",
       " '99662',\n",
       " '99811',\n",
       " '99859',\n",
       " 'V3000',\n",
       " 'V3001',\n",
       " 'V3101',\n",
       " 'V3401']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12469572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f5ccd19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mytemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5512e5af7df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set up test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer, \n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer_wrapper_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWrapperClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize_e\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_eos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     truncate_method=\"tail\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mytemplate' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_projects",
   "language": "python",
   "name": "nlp_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
